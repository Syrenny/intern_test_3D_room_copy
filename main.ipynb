{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-09T08:33:05.121237800Z",
     "start_time": "2024-02-09T08:33:03.205288800Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Загрузка необходимых данных "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "820b224568a3552c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"data/test_object_lu.json\", \"r\") as file:\n",
    "    map_objects = json.load(file)\n",
    "    \n",
    "partition = cv2.imread('data/partition.jpg')\n",
    "v_corners = np.load(\"data/v_corners.npy\")\n",
    "h_corners = np.load(\"data/h_corners.npy\")\n",
    "panorama = cv2.imread(\"data/image_1024_aligned_rgb.png\")\n",
    "depth = np.load(\"data/depth_map.npy\") * 1000 # in millimeters "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T08:33:05.164942800Z",
     "start_time": "2024-02-09T08:33:05.109235100Z"
    }
   },
   "id": "e71a3ffa0912992d",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 1024)\n",
      "6101.31\n",
      "[[1214.8892 1214.8892 1214.8892 ... 1214.8892 1214.8892 1214.8892]\n",
      " [1214.9348 1214.9348 1214.9348 ... 1214.9348 1214.9348 1214.9348]\n",
      " [1215.0264 1215.0264 1215.0264 ... 1215.0264 1215.0264 1215.0264]\n",
      " ...\n",
      " [1600.1882 1600.1882 1600.1882 ... 1600.1882 1600.1882 1600.1882]\n",
      " [1600.0677 1600.0677 1600.0677 ... 1600.0677 1600.0677 1600.0677]\n",
      " [1600.0076 1600.0076 1600.0076 ... 1600.0076 1600.0076 1600.0076]]\n"
     ]
    }
   ],
   "source": [
    "print(depth.shape)\n",
    "print(depth.max())\n",
    "print(depth)\n",
    "# Нормализация данных с камеры глубины\n",
    "scaled_depth = ((depth - np.min(depth)) / (np.max(depth) - np.min(depth)) * 255).astype(np.uint8)\n",
    "cv2.imshow('Depth Image', scaled_depth)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T08:33:08.972034700Z",
     "start_time": "2024-02-09T08:33:07.450028800Z"
    }
   },
   "id": "7345ea0efa426f33",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Загрузить изображения\n",
    "alpha = 0.7\n",
    "\n",
    "# Преобразовать глубину в трехканальное изображение\n",
    "depth_colored = cv2.applyColorMap((scaled_depth * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "\n",
    "# Наложить изображения\n",
    "overlay = cv2.addWeighted(panorama, alpha, depth_colored, 1 - alpha, 0)\n",
    "\n",
    "# Вывести результат\n",
    "cv2.imshow('Overlay', overlay)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T17:43:03.424753Z",
     "start_time": "2024-02-08T17:40:25.832173700Z"
    }
   },
   "id": "91739aba9e1c40c6",
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  30.914364  222.41164 ]\n",
      " [  30.914364  298.64883 ]\n",
      " [ 363.15613   140.81924 ]\n",
      " [ 363.15613   392.54047 ]\n",
      " [ 672.78357   149.66058 ]\n",
      " [ 672.78357   383.4991  ]\n",
      " [ 801.5895    137.09825 ]\n",
      " [ 801.5895    396.26495 ]\n",
      " [ 845.40314    76.09795 ]\n",
      " [ 845.40314   451.50623 ]\n",
      " [1008.1279    221.95033 ]\n",
      " [1008.1279    299.23853 ]]\n"
     ]
    }
   ],
   "source": [
    "cv2.imshow(\"source_image\", panorama)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print(v_corners)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T15:16:56.506991Z",
     "start_time": "2024-02-08T15:16:56.063513100Z"
    }
   },
   "id": "726b51aeffb24133",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of the line: 30\n",
      "end of the line: 363\n",
      "[[30, 222.71733], [62, 192.55711], [94, 169.15553], [126, 150.01512], [158, 136.72841], [190, 129.05185], [222, 124.01126], [254, 122.649155], [286, 123.07381], [318, 126.99274], [350, 135.25735]]\n"
     ]
    }
   ],
   "source": [
    "start = int(v_corners[0][0])\n",
    "print(\"start of the line:\", start)\n",
    "end = int(v_corners[2][0])\n",
    "print(\"end of the line:\", end)\n",
    "line = []\n",
    "for x in range(start, end+1, 32):\n",
    "    line.append([x, h_corners[:, x][0]])\n",
    "print(line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T06:28:37.209457400Z",
     "start_time": "2024-02-09T06:28:37.154256200Z"
    }
   },
   "id": "f0f1f1e91b778535",
   "execution_count": 154
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30.914364 222.41164 ] [ 30.914364 298.64883 ] [363.15613 140.81924] [363.15613 392.54047]\n",
      "[363.15613 140.81924] [363.15613 392.54047] [672.78357 149.66058] [672.78357 383.4991 ]\n",
      "[672.78357 149.66058] [672.78357 383.4991 ] [801.5895  137.09825] [801.5895  396.26495]\n",
      "[801.5895  137.09825] [801.5895  396.26495] [845.40314  76.09795] [845.40314 451.50623]\n",
      "[845.40314  76.09795] [845.40314 451.50623] [1008.1279   221.95033] [1008.1279   299.23853]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(v_corners) - 2, 2):\n",
    "    print(v_corners[i], v_corners[i + 1], v_corners[i + 2], v_corners[i + 3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T15:16:56.582308Z",
     "start_time": "2024-02-08T15:16:56.508988600Z"
    }
   },
   "id": "bab1de96c9722a74",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[221.67708 221.43863 221.38431 ... 222.38773 223.78665 223.0257 ]\n",
      " [299.86584 298.79175 299.72705 ... 298.76703 297.46896 299.3693 ]]\n"
     ]
    }
   ],
   "source": [
    "print(h_corners)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T15:16:56.584300600Z",
     "start_time": "2024-02-08T15:16:56.524991300Z"
    }
   },
   "id": "c6cce8a3069ae207",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "print(panorama.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T15:16:56.664670900Z",
     "start_time": "2024-02-08T15:16:56.539991200Z"
    }
   },
   "id": "43eee3934ea5b815",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "84afb24236e4d4a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Влоб"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf1357027606bc20"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_rows = 250\n",
    "num_columns = 1\n",
    "channels = 3  # для цветных изображений (BGR)\n",
    "new_image = np.zeros((num_rows, num_columns, channels), dtype=np.uint8)\n",
    "for i in range(h_corners.shape[1]):\n",
    "    lower, upper = h_corners[:,i].astype(int)\n",
    "    sliced = panorama[:, i][lower:upper]\n",
    "    resized = cv2.resize(sliced, (3, 250)).reshape((250, 1, 3))\n",
    "    new_image = np.hstack([new_image, resized])\n",
    "    \n",
    "cv2.imshow(\"new_image\", new_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T15:16:57.253844900Z",
     "start_time": "2024-02-08T15:16:56.558142900Z"
    }
   },
   "id": "2cb251d2ac78c64",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Сначала убираем вертикальное искажение, затем коррекция перспективы"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ac443ff596b9fea"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float32' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m sequence \u001B[38;5;241m=\u001B[39m upper_sequence \u001B[38;5;241m-\u001B[39m lower_sequence\n\u001B[0;32m     19\u001B[0m panorama_copy \u001B[38;5;241m=\u001B[39m panorama\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m---> 20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m new_size, panorama_pos, seq_pos \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sequence\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m), \u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mleft_lower\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright_lower\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mrange\u001B[39m(width)):\n\u001B[0;32m     21\u001B[0m     lower, upper \u001B[38;5;241m=\u001B[39m h_corners[:,panorama_pos]\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n\u001B[0;32m     22\u001B[0m     sliced \u001B[38;5;241m=\u001B[39m panorama_copy[:, panorama_pos][lower:upper]\n",
      "\u001B[1;31mTypeError\u001B[0m: 'numpy.float32' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "pts_plane = [[[0, 0], [0, 250], [602, 0], [602, 250]],\n",
    "             [[0, 0], [0, 250], [205, 0], [205, 250]],\n",
    "             [[0, 0], [0, 250], [164, 0], [164, 250]],\n",
    "             [[0, 0], [0, 250], [40, 0], [40, 250]],\n",
    "             [[0, 0], [0, 250], [438, 0], [438, 250]]]\n",
    "\n",
    "for i in range(0, len(v_corners) - 2, 2):\n",
    "    area_idx = i // 2\n",
    "    # Координаты для ключевых точек областей на исходной панораме\n",
    "    left_lower, left_upper, right_lower, right_upper = v_corners[i], v_corners[i + 1], v_corners[i + 2], v_corners[i + 3]\n",
    "    # Нахождение новой высоты для каждого столбца области \n",
    "    v_corners = v_corners.astype(int)\n",
    "    # Ширина области на исходной панораме\n",
    "    width = int(abs(left_upper[0] - right_upper[0]))\n",
    "    upper_sequence = np.linspace(left_upper[1], right_upper[1], width).astype(int)\n",
    "    lower_sequence = np.linspace(left_lower[1], right_lower[1], width).astype(int)\n",
    "    sequence = upper_sequence - lower_sequence\n",
    "    \n",
    "    panorama_copy = panorama.copy()\n",
    "    for new_size, panorama_pos, seq_pos in zip(sequence.astype(int), range(left_lower[0], right_lower[0]), range(width)):\n",
    "        lower, upper = h_corners[:,panorama_pos].astype(int)\n",
    "        sliced = panorama_copy[:, panorama_pos][lower:upper]\n",
    "        resized = cv2.resize(sliced, (3, new_size))\n",
    "        panorama_copy[:, panorama_pos][lower_sequence[seq_pos]:upper_sequence[seq_pos]] = resized\n",
    "        \n",
    "    # Отображение результата\n",
    "    cv2.imshow('new_panorama', panorama_copy)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Определение ключевых точек на панораме и плоскости\n",
    "    pts_panorama = np.float32([left_lower, left_upper, right_lower, right_upper])\n",
    "    \n",
    "    # Вычисление матрицы преобразования\n",
    "    matrix = cv2.getPerspectiveTransform(pts_panorama, np.float32(pts_plane[area_idx]))\n",
    "    \n",
    "    # Применение преобразования\n",
    "    result = cv2.warpPerspective(panorama_copy, matrix, [pts_plane[area_idx][2][0], 250])\n",
    "    \n",
    "    # Отображение результата\n",
    "    cv2.imshow('Projected Image', result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T15:16:58.111523500Z",
     "start_time": "2024-02-08T15:16:57.277889600Z"
    }
   },
   "id": "e8fd91d43fcd623e",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "concatenated_panorama = np.concatenate((partition, partition), axis=1)\n",
    "cv2.imshow(\"Concatenated\", concatenated_panorama)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-08T15:16:58.119524100Z"
    }
   },
   "id": "145afec1b16e6ba3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def depth_to_coordinates(depth_map, fx, fy, cx, cy):\n",
    "    \"\"\"\n",
    "    Преобразует карту глубины в 3D координаты.\n",
    "\n",
    "    Параметры:\n",
    "    - depth_map: Карта глубины.\n",
    "    - fx, fy: Фокусные расстояния камеры.\n",
    "    - cx, cy: Координаты центра изображения.\n",
    "\n",
    "    Возвращает массив 3D координат в мировой системе координат.\n",
    "    \"\"\"\n",
    "    rows, cols = depth_map.shape\n",
    "    coordinates = np.zeros((rows, cols, 3), dtype=np.float32)\n",
    "\n",
    "    for y in range(rows):\n",
    "        for x in range(cols):\n",
    "            depth = depth_map[y, x]\n",
    "            coordinates[y, x, 0] = (x - cx) * depth / fx\n",
    "            coordinates[y, x, 1] = (y - cy) * depth / fy\n",
    "            coordinates[y, x, 2] = depth\n",
    "\n",
    "    return coordinates\n",
    "\n",
    " # Загрузка карты глубины\n",
    "depth_map = depth\n",
    "\n",
    "# Параметры камеры (пример значения)\n",
    "fx = 500.0  # фокусное расстояние по горизонтали\n",
    "fy = 500.0  # фокусное расстояние по вертикали\n",
    "cx = depth_map.shape[1] / 2.0  # координата центра изображения по горизонтали\n",
    "cy = depth_map.shape[0] / 2.0  # координата центра изображения по вертикали\n",
    "\n",
    "# Преобразование карты глубины в 3D координаты\n",
    "coordinates = depth_to_coordinates(depth_map, fx, fy, cx, cy)\n",
    "\n",
    "# Вывод 3D координат первой точки\n",
    "print(\"3D Coordinates of the first point:\", coordinates)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-08T15:16:58.120524500Z"
    }
   },
   "id": "80ee17c76d9f8a58",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "# Создание случайного облака точек для примера\n",
    "np.random.seed(123)\n",
    "points = np.random.rand(100, 3)\n",
    "\n",
    "# Создание объекта облака точек\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "# Визуализация облака точек\n",
    "o3d.visualization.draw_geometries([point_cloud])\n",
    "# Сохранение облака точек\n",
    "o3d.io.write_point_cloud(\"point_cloud.ply\", point_cloud)\n",
    "\n",
    "# Загрузка облака точек\n",
    "loaded_point_cloud = o3d.io.read_point_cloud(\"point_cloud.ply\")\n",
    "o3d.visualization.draw_geometries([loaded_point_cloud])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-08T15:16:58.123524400Z"
    }
   },
   "id": "53fc0fd1bafebe6d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Получение ширины и высоты изображения\n",
    "height, width, _ = panorama.shape\n",
    "\n",
    "# Разбиение изображения на 6 частей по горизонтали\n",
    "num_parts = 6\n",
    "part_width = width // num_parts\n",
    "\n",
    "# Массив для хранения частей изображения\n",
    "image_parts = []\n",
    "depth_parts = []\n",
    "for i in range(num_parts):\n",
    "    # Вычисление координат для текущей части\n",
    "    start_x = i * part_width\n",
    "    end_x = (i + 1) * part_width\n",
    "\n",
    "    # Добавление текущей части в массив\n",
    "    image_parts.append(panorama[:, start_x:end_x, :])\n",
    "    depth_parts.append(depth[:, start_x:end_x])\n",
    "\n",
    "# Теперь у вас есть массив image_parts, содержащий 6 частей изображения,\n",
    "# к которым можно обращаться по индексам, например, image_parts[0] для первой части.\n",
    "\n",
    "# Пример вывода каждой части для проверки\n",
    "for i, part in enumerate(image_parts):\n",
    "    cv2.imshow(f'Part {i+1}', part)\n",
    "    cv2.imshow(f'Part {i+1}', depth_parts[i])\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T17:24:29.044693900Z",
     "start_time": "2024-02-08T17:24:27.461211600Z"
    }
   },
   "id": "81bd25ece4629c61",
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Получение ширины изображения\n",
    "# Взятие половины изображения по горизонтали\n",
    "rgb_image = panorama\n",
    "depth_image = depth\n",
    "width = rgb_image.shape[1]\n",
    "# Создание облака точек из данных камеры RGB-D\n",
    "rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    o3d.geometry.Image(rgb_image), \n",
    "    o3d.geometry.Image(depth_image)\n",
    ")\n",
    "fx = 0.6  # фокусное расстояние по горизонтали\n",
    "fy = 0.6  # фокусное расстояние по вертикали\n",
    "cx = depth_image.shape[1] / 2.0  # координата центра изображения по горизонтали\n",
    "cy = depth_image.shape[0] / 2.0  # координата центра изображения по вертикали\n",
    "\n",
    "intrinsics = o3d.camera.PinholeCameraIntrinsic(\n",
    "    width=rgb_image.shape[1], height=rgb_image.shape[0],\n",
    "    fx=fx, fy=fy, cx=cx, cy=cy\n",
    ")\n",
    "\n",
    "pcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "    rgbd_image,\n",
    "    intrinsics)\n",
    "# Flip it, otherwise the pointcloud will be upside down\n",
    "pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "# Визуализация облака точек\n",
    "o3d.visualization.draw_geometries([pcd])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T05:17:47.449029200Z",
     "start_time": "2024-02-09T05:17:40.973219600Z"
    }
   },
   "id": "6a35f1671267a0a7",
   "execution_count": 141
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# outliers removal\n",
    "cl, ind = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=20.0)\n",
    "pcd = pcd.select_by_index(ind)\n",
    "\n",
    "# estimate normals\n",
    "pcd.estimate_normals()\n",
    "pcd.orient_normals_to_align_with_direction()\n",
    "\n",
    "# surface reconstruction\n",
    "mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=10, n_threads=1)[0]\n",
    "\n",
    "# rotate the mesh\n",
    "rotation = mesh.get_rotation_matrix_from_xyz((np.pi, 0, 0))\n",
    "mesh.rotate(rotation, center=(0, 0, 0))\n",
    "\n",
    "# save the mesh\n",
    "o3d.io.write_triangle_mesh(f'./mesh.obj', mesh)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T04:13:19.716711900Z",
     "start_time": "2024-02-09T04:12:27.338771800Z"
    }
   },
   "id": "7eb317685f4a2862",
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load and prepare BMP texture\n",
    "bmp = panorama\n",
    "\n",
    "# 180x90 degree\n",
    "xs, ys = bmp.shape[1], bmp.shape[0]\n",
    "da = np.pi / (xs - 1)\n",
    "db = 0.5 * np.pi / (ys - 1)\n",
    "b = -0.25 * np.pi\n",
    "\n",
    "# Process all pixels\n",
    "pnt = []\n",
    "for y in range(ys):\n",
    "    for x in range(xs):\n",
    "        # Pixel intensity from texture\n",
    "        r = bmp[y, x] / 255.0\n",
    "        # Convert to 3D\n",
    "        xx = r * np.cos(x * da) * np.cos(b)\n",
    "        yy = r * np.sin(x * da) * np.cos(b)\n",
    "        zz = r * np.sin(b)\n",
    "        # Store in point cloud\n",
    "        pnt.extend([xx, yy, zz])\n",
    "\n",
    "# Reshape the array to Nx3\n",
    "point_cloud = np.array(pnt).reshape(-1, 3)\n",
    "\n",
    "# Convert NumPy array to Open3D point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(point_cloud)\n",
    "\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([pcd])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T18:23:48.184779100Z",
     "start_time": "2024-02-08T18:23:31.674427600Z"
    }
   },
   "id": "7f96f7aefa333db1",
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved part 1 to parts/part1.jpg\n",
      "Saved part 2 to parts/part2.jpg\n",
      "Saved part 3 to parts/part3.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "image = panorama\n",
    "\n",
    "# Получение размеров изображения\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Разделение изображения на 6 частей по горизонтали\n",
    "num_parts = 3\n",
    "part_width = width // num_parts\n",
    "\n",
    "# Создание папки для частей, если ее нет\n",
    "output_folder = 'parts'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Сохранение каждой части изображения\n",
    "for i in range(num_parts):\n",
    "    start_col = i * part_width\n",
    "    end_col = (i + 1) * part_width\n",
    "\n",
    "    # Выделение части изображения\n",
    "    image_part = image[:, start_col:end_col, :]\n",
    "\n",
    "    # Сохранение части изображения\n",
    "    part_filename = f\"{output_folder}/part{i + 1}.jpg\"\n",
    "    cv2.imwrite(part_filename, image_part)\n",
    "\n",
    "    print(f\"Saved part {i + 1} to {part_filename}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T06:58:52.826146300Z",
     "start_time": "2024-02-09T06:58:52.779143300Z"
    }
   },
   "id": "9fe2922207eae68a",
   "execution_count": 179
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved part 1 to parts_with_padding/part1.jpg\n",
      "Saved part 2 to parts_with_padding/part2.jpg\n",
      "Saved part 3 to parts_with_padding/part3.jpg\n",
      "Saved part 4 to parts_with_padding/part4.jpg\n",
      "Saved part 5 to parts_with_padding/part5.jpg\n",
      "Saved part 6 to parts_with_padding/part6.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Загрузка изображения\n",
    "image_path = 'data/image_1024_aligned_rgb.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Размер паддинга\n",
    "padding_size = 200\n",
    "\n",
    "# Добавление паддинга\n",
    "\n",
    "\n",
    "# Получение размеров изображения с паддингом\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Разделение изображения на 6 частей по горизонтали\n",
    "num_parts = 6\n",
    "part_width = width // num_parts\n",
    "\n",
    "# Создание папки для частей, если ее нет\n",
    "output_folder = 'parts_with_padding'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Сохранение каждой части изображения\n",
    "for i in range(num_parts):\n",
    "    start_col = i * part_width\n",
    "    end_col = (i + 1) * part_width\n",
    "\n",
    "    # Выделение части изображения с паддингом\n",
    "    image_part = image[:, start_col:end_col, :]\n",
    "    image_with_padding = cv2.copyMakeBorder(image_part, padding_size, padding_size, padding_size, padding_size, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    # Сохранение части изображения\n",
    "    part_filename = f\"{output_folder}/part{i + 1}.jpg\"\n",
    "    cv2.imwrite(part_filename, image_with_padding)\n",
    "\n",
    "    print(f\"Saved part {i + 1} to {part_filename}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T08:17:02.772674700Z",
     "start_time": "2024-02-09T08:17:02.665867500Z"
    }
   },
   "id": "e34de2306e34e9dd",
   "execution_count": 137
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from defisheye import Defisheye\n",
    "import cv2 \n",
    "\n",
    "dtype = 'linear'\n",
    "format = 'fullframe'\n",
    "fov = 180\n",
    "pfov = 120\n",
    "\n",
    "\n",
    "img = \"parts_with_padding/part1.jpg\"\n",
    "\n",
    "obj = Defisheye(img, dtype=dtype, format=format, fov=fov, pfov=pfov)\n",
    "\n",
    "# To use the converted image in memory\n",
    "\n",
    "new_image = obj.convert()\n",
    "\n",
    "cv2.imshow(\"1\", new_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T08:19:58.569967100Z",
     "start_time": "2024-02-09T08:19:47.747053300Z"
    }
   },
   "id": "4258a7db1828c28e",
   "execution_count": 148
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:866: error: (-215:Assertion failed) trackbar in function 'cv::getTrackbarPos'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[100], line 21\u001B[0m, in \u001B[0;36mon_trackbar_change\u001B[1;34m(val)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_trackbar_change\u001B[39m(val):\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;66;03m# Получение текущих положений ползунков\u001B[39;00m\n\u001B[0;32m     20\u001B[0m     k1 \u001B[38;5;241m=\u001B[39m (cv2\u001B[38;5;241m.\u001B[39mgetTrackbarPos(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mK1\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUndistorted Image\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1000\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1000000000.0\u001B[39m  \u001B[38;5;66;03m# Ограничиваем диапазон от -1.0 до 1.0\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m     k2 \u001B[38;5;241m=\u001B[39m (\u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetTrackbarPos\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mK2\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mUndistorted Image\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1000\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1000000000000000.0\u001B[39m  \u001B[38;5;66;03m# Ограничиваем диапазон от -1.0 до 1.0\u001B[39;00m\n\u001B[0;32m     22\u001B[0m     k3 \u001B[38;5;241m=\u001B[39m (cv2\u001B[38;5;241m.\u001B[39mgetTrackbarPos(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mK3\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUndistorted Image\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1000\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m10000000\u001B[39m  \u001B[38;5;66;03m# Ограничиваем диапазон от -1.0 до 1.0\u001B[39;00m\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;66;03m# Применение устранения barrel distortion\u001B[39;00m\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:866: error: (-215:Assertion failed) trackbar in function 'cv::getTrackbarPos'\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:866: error: (-215:Assertion failed) trackbar in function 'cv::getTrackbarPos'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[100], line 22\u001B[0m, in \u001B[0;36mon_trackbar_change\u001B[1;34m(val)\u001B[0m\n\u001B[0;32m     20\u001B[0m k1 \u001B[38;5;241m=\u001B[39m (cv2\u001B[38;5;241m.\u001B[39mgetTrackbarPos(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mK1\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUndistorted Image\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1000\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1000000000.0\u001B[39m  \u001B[38;5;66;03m# Ограничиваем диапазон от -1.0 до 1.0\u001B[39;00m\n\u001B[0;32m     21\u001B[0m k2 \u001B[38;5;241m=\u001B[39m (cv2\u001B[38;5;241m.\u001B[39mgetTrackbarPos(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mK2\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUndistorted Image\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1000\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1000000000000000.0\u001B[39m  \u001B[38;5;66;03m# Ограничиваем диапазон от -1.0 до 1.0\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m k3 \u001B[38;5;241m=\u001B[39m (\u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetTrackbarPos\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mK3\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mUndistorted Image\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1000\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m10000000\u001B[39m  \u001B[38;5;66;03m# Ограничиваем диапазон от -1.0 до 1.0\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# Применение устранения barrel distortion\u001B[39;00m\n\u001B[0;32m     25\u001B[0m undistorted \u001B[38;5;241m=\u001B[39m undistort_image(original_image, k1, k2, k3)\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:866: error: (-215:Assertion failed) trackbar in function 'cv::getTrackbarPos'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Функция обработки изображения с устранением barrel distortion\n",
    "def undistort_image(image, k1, k2, k3):\n",
    "    h, w = image.shape[:2]\n",
    "    K = np.eye(3)\n",
    "    \n",
    "    # Коэффициенты искажения\n",
    "    dist_coeffs = np.array([k1, k2, k3, 0.0, 0.0])\n",
    "    \n",
    "    # Устранение barrel distortion\n",
    "    undistorted_image = cv2.undistort(image, K, dist_coeffs)\n",
    "    \n",
    "    return undistorted_image\n",
    "\n",
    "# Функция обратного вызова для ползунков\n",
    "def on_trackbar_change(val):\n",
    "    # Получение текущих положений ползунков\n",
    "    k1 = (cv2.getTrackbarPos('K1', 'Undistorted Image') - 1000) / 1000000000.0  # Ограничиваем диапазон от -1.0 до 1.0\n",
    "    k2 = (cv2.getTrackbarPos('K2', 'Undistorted Image') - 1000) / 1000000000000000.0  # Ограничиваем диапазон от -1.0 до 1.0\n",
    "    k3 = (cv2.getTrackbarPos('K3', 'Undistorted Image') - 1000) / 10000000  # Ограничиваем диапазон от -1.0 до 1.0\n",
    "\n",
    "    # Применение устранения barrel distortion\n",
    "    undistorted = undistort_image(original_image, k1, k2, k3)\n",
    "    \n",
    "    # Отображение обработанного изображения\n",
    "    cv2.imshow('Undistorted Image', undistorted)\n",
    "\n",
    "# Загрузка изображения\n",
    "image_path = \"parts_with_padding/part1.jpg\"\n",
    "original_image = cv2.imread(image_path)\n",
    "\n",
    "# Создание окна\n",
    "cv2.namedWindow('Undistorted Image')\n",
    "\n",
    "# Создание ползунков\n",
    "cv2.createTrackbar('K1', 'Undistorted Image', 1000, 2000, on_trackbar_change)\n",
    "cv2.createTrackbar('K2', 'Undistorted Image', 1000, 2000, on_trackbar_change)\n",
    "cv2.createTrackbar('K3', 'Undistorted Image', 1000, 2000, on_trackbar_change)\n",
    "\n",
    "# Инициализация положений ползунков\n",
    "cv2.setTrackbarPos('K1', 'Undistorted Image', 1000)\n",
    "cv2.setTrackbarPos('K2', 'Undistorted Image', 1000)\n",
    "cv2.setTrackbarPos('K3', 'Undistorted Image', 1000)\n",
    "\n",
    "# Инициализация изображения с устранением искажения при старте\n",
    "on_trackbar_change(0)\n",
    "\n",
    "# Ожидание нажатия клавиши\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T07:40:13.508526500Z",
     "start_time": "2024-02-09T07:39:49.351920400Z"
    }
   },
   "id": "565fea84c3ba8fe0",
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def stretch_image(image, stretch_factor):\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # Создание матрицы преобразования для растяжения\n",
    "    transformation_matrix = np.array([[stretch_factor, 0, 0], [0, 1, 0]], dtype=np.float32)\n",
    "    \n",
    "    # Применение преобразования к изображению\n",
    "    stretched_image = cv2.warpAffine(image, transformation_matrix, (w, h))\n",
    "    \n",
    "    return stretched_image\n",
    "\n",
    "# Загрузка изображения\n",
    "image_path = \"parts_with_padding/part1.jpg\"\n",
    "original_image = cv2.imread(image_path)\n",
    "\n",
    "# Установка коэффициента растяжения (замените его на необходимое значение)\n",
    "stretch_factor = 4.5\n",
    "\n",
    "# Применение растяжения\n",
    "stretched_image = stretch_image(original_image, stretch_factor)\n",
    "\n",
    "# Отображение изображений\n",
    "cv2.imshow('Original Image', original_image)\n",
    "cv2.imshow('Stretched Image', stretched_image)\n",
    "\n",
    "# Ожидание нажатия клавиши\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T07:46:15.913280400Z",
     "start_time": "2024-02-09T07:46:05.841609Z"
    }
   },
   "id": "e0349c6912b269b6",
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "def depth_to_pointcloud(depth_image, fx, fy, cx, cy):\n",
    "    # Получение координат точек из изображения глубины\n",
    "    rows, cols = depth_image.shape\n",
    "    y, x = np.indices((rows, cols))\n",
    "    z = depth_image / 1000.0  # Перевод из миллиметров в метры\n",
    "\n",
    "    # Конвертация в координаты в 3D пространстве\n",
    "    x3d = (x - cx) * z / fx\n",
    "    y3d = (y - cy) * z / fy\n",
    "\n",
    "    # Создание облака точек\n",
    "    points = np.column_stack((x3d.flatten(), y3d.flatten(), z.flatten()))\n",
    "    valid_points = points[np.isfinite(points).all(axis=1)]\n",
    "\n",
    "    return valid_points\n",
    "\n",
    "# Загрузка изображения глубины\n",
    "width = scaled_depth.shape[1]\n",
    "depth_image = scaled_depth\n",
    "# Отображение изображений\n",
    "cv2.imshow('Original Image', depth_image)\n",
    "\n",
    "# Ожидание нажатия клавиши\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# Калибровочные параметры камеры (замените их на ваши значения)\n",
    "fx = 550.0\n",
    "fy = 100.0\n",
    "cx = depth_image.shape[1] / 2\n",
    "cy = depth_image.shape[0] / 2\n",
    "\n",
    "# Преобразование изображения глубины в PointCloud\n",
    "pointcloud = depth_to_pointcloud(depth_image, fx, fy, cx, cy)\n",
    "\n",
    "# Создание объекта PointCloud в Open3D\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pointcloud)\n",
    "\n",
    "# Визуализация PointCloud\n",
    "o3d.visualization.draw_geometries([pcd])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T08:42:48.303381600Z",
     "start_time": "2024-02-09T08:42:36.289521700Z"
    }
   },
   "id": "69c57b47adf94b6c",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import map_coordinates\n",
    "\n",
    "\n",
    "def xyzcube(face_w):\n",
    "    '''\n",
    "    Return the xyz cordinates of the unit cube in [F R B L U D] format.\n",
    "    '''\n",
    "    out = np.zeros((face_w, face_w * 6, 3), np.float32)\n",
    "    rng = np.linspace(-0.5, 0.5, num=face_w, dtype=np.float32)\n",
    "    grid = np.stack(np.meshgrid(rng, -rng), -1)\n",
    "\n",
    "    # Front face (z = 0.5)\n",
    "    out[:, 0*face_w:1*face_w, [0, 1]] = grid\n",
    "    out[:, 0*face_w:1*face_w, 2] = 0.5\n",
    "\n",
    "    # Right face (x = 0.5)\n",
    "    out[:, 1*face_w:2*face_w, [2, 1]] = grid\n",
    "    out[:, 1*face_w:2*face_w, 0] = 0.5\n",
    "\n",
    "    # Back face (z = -0.5)\n",
    "    out[:, 2*face_w:3*face_w, [0, 1]] = grid\n",
    "    out[:, 2*face_w:3*face_w, 2] = -0.5\n",
    "\n",
    "    # Left face (x = -0.5)\n",
    "    out[:, 3*face_w:4*face_w, [2, 1]] = grid\n",
    "    out[:, 3*face_w:4*face_w, 0] = -0.5\n",
    "\n",
    "    # Up face (y = 0.5)\n",
    "    out[:, 4*face_w:5*face_w, [0, 2]] = grid\n",
    "    out[:, 4*face_w:5*face_w, 1] = 0.5\n",
    "\n",
    "    # Down face (y = -0.5)\n",
    "    out[:, 5*face_w:6*face_w, [0, 2]] = grid\n",
    "    out[:, 5*face_w:6*face_w, 1] = -0.5\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def equirect_uvgrid(h, w):\n",
    "    u = np.linspace(-np.pi, np.pi, num=w, dtype=np.float32)\n",
    "    v = np.linspace(np.pi, -np.pi, num=h, dtype=np.float32) / 2\n",
    "\n",
    "    return np.stack(np.meshgrid(u, v), axis=-1)\n",
    "\n",
    "\n",
    "def equirect_facetype(h, w):\n",
    "    '''\n",
    "    0F 1R 2B 3L 4U 5D\n",
    "    '''\n",
    "    tp = np.roll(np.arange(4).repeat(w // 4)[None, :].repeat(h, 0), 3 * w // 8, 1)\n",
    "\n",
    "    # Prepare ceil mask\n",
    "    mask = np.zeros((h, w // 4), np.bool)\n",
    "    idx = np.linspace(-np.pi, np.pi, w // 4) / 4\n",
    "    idx = h // 2 - np.round(np.arctan(np.cos(idx)) * h / np.pi).astype(int)\n",
    "    for i, j in enumerate(idx):\n",
    "        mask[:j, i] = 1\n",
    "    mask = np.roll(np.concatenate([mask] * 4, 1), 3 * w // 8, 1)\n",
    "\n",
    "    tp[mask] = 4\n",
    "    tp[np.flip(mask, 0)] = 5\n",
    "\n",
    "    return tp.astype(np.int32)\n",
    "\n",
    "\n",
    "def xyzpers(h_fov, v_fov, u, v, out_hw, in_rot):\n",
    "    out = np.ones((*out_hw, 3), np.float32)\n",
    "\n",
    "    x_max = np.tan(h_fov / 2)\n",
    "    y_max = np.tan(v_fov / 2)\n",
    "    x_rng = np.linspace(-x_max, x_max, num=out_hw[1], dtype=np.float32)\n",
    "    y_rng = np.linspace(-y_max, y_max, num=out_hw[0], dtype=np.float32)\n",
    "    out[..., :2] = np.stack(np.meshgrid(x_rng, -y_rng), -1)\n",
    "    Rx = rotation_matrix(v, [1, 0, 0])\n",
    "    Ry = rotation_matrix(u, [0, 1, 0])\n",
    "    Ri = rotation_matrix(in_rot, np.array([0, 0, 1.0]).dot(Rx).dot(Ry))\n",
    "\n",
    "    return out.dot(Rx).dot(Ry).dot(Ri)\n",
    "\n",
    "\n",
    "def xyz2uv(xyz):\n",
    "    '''\n",
    "    xyz: ndarray in shape of [..., 3]\n",
    "    '''\n",
    "    x, y, z = np.split(xyz, 3, axis=-1)\n",
    "    u = np.arctan2(x, z)\n",
    "    c = np.sqrt(x**2 + z**2)\n",
    "    v = np.arctan2(y, c)\n",
    "\n",
    "    return np.concatenate([u, v], axis=-1)\n",
    "\n",
    "\n",
    "def uv2unitxyz(uv):\n",
    "    u, v = np.split(uv, 2, axis=-1)\n",
    "    y = np.sin(v)\n",
    "    c = np.cos(v)\n",
    "    x = c * np.sin(u)\n",
    "    z = c * np.cos(u)\n",
    "\n",
    "    return np.concatenate([x, y, z], axis=-1)\n",
    "\n",
    "\n",
    "def uv2coor(uv, h, w):\n",
    "    '''\n",
    "    uv: ndarray in shape of [..., 2]\n",
    "    h: int, height of the equirectangular image\n",
    "    w: int, width of the equirectangular image\n",
    "    '''\n",
    "    u, v = np.split(uv, 2, axis=-1)\n",
    "    coor_x = (u / (2 * np.pi) + 0.5) * w - 0.5\n",
    "    coor_y = (-v / np.pi + 0.5) * h - 0.5\n",
    "\n",
    "    return np.concatenate([coor_x, coor_y], axis=-1)\n",
    "\n",
    "\n",
    "def coor2uv(coorxy, h, w):\n",
    "    coor_x, coor_y = np.split(coorxy, 2, axis=-1)\n",
    "    u = ((coor_x + 0.5) / w - 0.5) * 2 * np.pi\n",
    "    v = -((coor_y + 0.5) / h - 0.5) * np.pi\n",
    "\n",
    "    return np.concatenate([u, v], axis=-1)\n",
    "\n",
    "\n",
    "def sample_equirec(e_img, coor_xy, order):\n",
    "    w = e_img.shape[1]\n",
    "    coor_x, coor_y = np.split(coor_xy, 2, axis=-1)\n",
    "    pad_u = np.roll(e_img[[0]], w // 2, 1)\n",
    "    pad_d = np.roll(e_img[[-1]], w // 2, 1)\n",
    "    e_img = np.concatenate([e_img, pad_d, pad_u], 0)\n",
    "    return map_coordinates(e_img, [coor_y, coor_x],\n",
    "                           order=order, mode='wrap')[..., 0]\n",
    "\n",
    "\n",
    "def sample_cubefaces(cube_faces, tp, coor_y, coor_x, order):\n",
    "    cube_faces = cube_faces.copy()\n",
    "    cube_faces[1] = np.flip(cube_faces[1], 1)\n",
    "    cube_faces[2] = np.flip(cube_faces[2], 1)\n",
    "    cube_faces[4] = np.flip(cube_faces[4], 0)\n",
    "\n",
    "    # Pad up down\n",
    "    pad_ud = np.zeros((6, 2, cube_faces.shape[2]))\n",
    "    pad_ud[0, 0] = cube_faces[5, 0, :]\n",
    "    pad_ud[0, 1] = cube_faces[4, -1, :]\n",
    "    pad_ud[1, 0] = cube_faces[5, :, -1]\n",
    "    pad_ud[1, 1] = cube_faces[4, ::-1, -1]\n",
    "    pad_ud[2, 0] = cube_faces[5, -1, ::-1]\n",
    "    pad_ud[2, 1] = cube_faces[4, 0, ::-1]\n",
    "    pad_ud[3, 0] = cube_faces[5, ::-1, 0]\n",
    "    pad_ud[3, 1] = cube_faces[4, :, 0]\n",
    "    pad_ud[4, 0] = cube_faces[0, 0, :]\n",
    "    pad_ud[4, 1] = cube_faces[2, 0, ::-1]\n",
    "    pad_ud[5, 0] = cube_faces[2, -1, ::-1]\n",
    "    pad_ud[5, 1] = cube_faces[0, -1, :]\n",
    "    cube_faces = np.concatenate([cube_faces, pad_ud], 1)\n",
    "\n",
    "    # Pad left right\n",
    "    pad_lr = np.zeros((6, cube_faces.shape[1], 2))\n",
    "    pad_lr[0, :, 0] = cube_faces[1, :, 0]\n",
    "    pad_lr[0, :, 1] = cube_faces[3, :, -1]\n",
    "    pad_lr[1, :, 0] = cube_faces[2, :, 0]\n",
    "    pad_lr[1, :, 1] = cube_faces[0, :, -1]\n",
    "    pad_lr[2, :, 0] = cube_faces[3, :, 0]\n",
    "    pad_lr[2, :, 1] = cube_faces[1, :, -1]\n",
    "    pad_lr[3, :, 0] = cube_faces[0, :, 0]\n",
    "    pad_lr[3, :, 1] = cube_faces[2, :, -1]\n",
    "    pad_lr[4, 1:-1, 0] = cube_faces[1, 0, ::-1]\n",
    "    pad_lr[4, 1:-1, 1] = cube_faces[3, 0, :]\n",
    "    pad_lr[5, 1:-1, 0] = cube_faces[1, -2, :]\n",
    "    pad_lr[5, 1:-1, 1] = cube_faces[3, -2, ::-1]\n",
    "    cube_faces = np.concatenate([cube_faces, pad_lr], 2)\n",
    "\n",
    "    return map_coordinates(cube_faces, [tp, coor_y, coor_x], order=order, mode='wrap')\n",
    "\n",
    "\n",
    "def cube_h2list(cube_h):\n",
    "    assert cube_h.shape[0] * 6 == cube_h.shape[1]\n",
    "    return np.split(cube_h, 6, axis=1)\n",
    "\n",
    "\n",
    "def cube_list2h(cube_list):\n",
    "    assert len(cube_list) == 6\n",
    "    assert sum(face.shape == cube_list[0].shape for face in cube_list) == 6\n",
    "    return np.concatenate(cube_list, axis=1)\n",
    "\n",
    "\n",
    "def cube_h2dict(cube_h):\n",
    "    cube_list = cube_h2list(cube_h)\n",
    "    return dict([(k, cube_list[i])\n",
    "                 for i, k in enumerate(['F', 'R', 'B', 'L', 'U', 'D'])])\n",
    "\n",
    "\n",
    "def cube_dict2h(cube_dict, face_k=['F', 'R', 'B', 'L', 'U', 'D']):\n",
    "    assert len(face_k) == 6\n",
    "    return cube_list2h([cube_dict[k] for k in face_k])\n",
    "\n",
    "\n",
    "def cube_h2dice(cube_h):\n",
    "    assert cube_h.shape[0] * 6 == cube_h.shape[1]\n",
    "    w = cube_h.shape[0]\n",
    "    cube_dice = np.zeros((w * 3, w * 4, cube_h.shape[2]), dtype=cube_h.dtype)\n",
    "    cube_list = cube_h2list(cube_h)\n",
    "    # Order: F R B L U D\n",
    "    sxy = [(1, 1), (2, 1), (3, 1), (0, 1), (1, 0), (1, 2)]\n",
    "    for i, (sx, sy) in enumerate(sxy):\n",
    "        face = cube_list[i]\n",
    "        if i in [1, 2]:\n",
    "            face = np.flip(face, axis=1)\n",
    "        if i == 4:\n",
    "            face = np.flip(face, axis=0)\n",
    "        cube_dice[sy*w:(sy+1)*w, sx*w:(sx+1)*w] = face\n",
    "    return cube_dice\n",
    "\n",
    "\n",
    "def cube_dice2h(cube_dice):\n",
    "    w = cube_dice.shape[0] // 3\n",
    "    assert cube_dice.shape[0] == w * 3 and cube_dice.shape[1] == w * 4\n",
    "    cube_h = np.zeros((w, w * 6, cube_dice.shape[2]), dtype=cube_dice.dtype)\n",
    "    # Order: F R B L U D\n",
    "    sxy = [(1, 1), (2, 1), (3, 1), (0, 1), (1, 0), (1, 2)]\n",
    "    for i, (sx, sy) in enumerate(sxy):\n",
    "        face = cube_dice[sy*w:(sy+1)*w, sx*w:(sx+1)*w]\n",
    "        if i in [1, 2]:\n",
    "            face = np.flip(face, axis=1)\n",
    "        if i == 4:\n",
    "            face = np.flip(face, axis=0)\n",
    "        cube_h[:, i*w:(i+1)*w] = face\n",
    "    return cube_h\n",
    "\n",
    "\n",
    "def rotation_matrix(rad, ax):\n",
    "    ax = np.array(ax)\n",
    "    assert len(ax.shape) == 1 and ax.shape[0] == 3\n",
    "    ax = ax / np.sqrt((ax**2).sum())\n",
    "    R = np.diag([np.cos(rad)] * 3)\n",
    "    R = R + np.outer(ax, ax) * (1.0 - np.cos(rad))\n",
    "\n",
    "    ax = ax * np.sin(rad)\n",
    "    R = R + np.array([[0, -ax[2], ax[1]],\n",
    "                      [ax[2], 0, -ax[0]],\n",
    "                      [-ax[1], ax[0], 0]])\n",
    "\n",
    "    return R"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T08:58:28.266185300Z",
     "start_time": "2024-02-09T08:58:27.334835600Z"
    }
   },
   "id": "e0a7675d8ef27f5c",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 1024\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def e2p(e_img, fov_deg, u_deg, v_deg, out_hw, in_rot_deg=0, mode='bilinear'):\n",
    "    '''\n",
    "    e_img:   ndarray in shape of [H, W, *]\n",
    "    fov_deg: scalar or (scalar, scalar) field of view in degree\n",
    "    u_deg:   horizon viewing angle in range [-180, 180]\n",
    "    v_deg:   vertical viewing angle in range [-90, 90]\n",
    "    '''\n",
    "    assert len(e_img.shape) == 3\n",
    "    h, w = e_img.shape[:2]\n",
    "\n",
    "    try:\n",
    "        h_fov, v_fov = fov_deg[0] * np.pi / 180, fov_deg[1] * np.pi / 180\n",
    "    except:\n",
    "        h_fov, v_fov = fov, fov\n",
    "    in_rot = in_rot_deg * np.pi / 180\n",
    "\n",
    "    if mode == 'bilinear':\n",
    "        order = 1\n",
    "    elif mode == 'nearest':\n",
    "        order = 0\n",
    "    else:\n",
    "        raise NotImplementedError('unknown mode')\n",
    "\n",
    "    u = -u_deg * np.pi / 180\n",
    "    v = v_deg * np.pi / 180\n",
    "    xyz = xyzpers(h_fov, v_fov, u, v, out_hw, in_rot)\n",
    "    uv = xyz2uv(xyz)\n",
    "    coor_xy = uv2coor(uv, h, w)\n",
    "\n",
    "    pers_img = np.stack([\n",
    "        sample_equirec(e_img[..., i], coor_xy, order=order)\n",
    "        for i in range(e_img.shape[2])\n",
    "    ], axis=-1)\n",
    "\n",
    "    return pers_img\n",
    "\n",
    "\n",
    "equirectangular_img = panorama\n",
    "h, w = equirectangular_img.shape[:2]\n",
    "print(h, w)\n",
    "views = [['f', (120, 120), 0, 0, 0],\n",
    "         ['r', (120, 120), 90, 0, 0],\n",
    "         ['b', (120, 120), 180, 0, 0],\n",
    "         ['l', (120, 120), -90, 0, 0],\n",
    "         ['u', (120, 120), 0, 90, 0],\n",
    "         ['d', (120, 120), 0, -90, 0]]\n",
    "# Углы обзора\n",
    "# fov_deg = (120, 120)\n",
    "# u_deg = 0\n",
    "# v_deg = 90\n",
    "\n",
    "# Размер выходного изображения\n",
    "# out_hw = (1200, 900)\n",
    "for face_k, fov_deg, u_deg, v_deg, in_rot in views:\n",
    "    out_hw = (\n",
    "        (512 * fov_deg[1]) // 180 * 2,\n",
    "        (1024 * fov_deg[0]) // 360 * 2,\n",
    "    )\n",
    "    # Угол поворота входного изображения\n",
    "    in_rot_deg = 0\n",
    "    \n",
    "    # Режим интерполяции\n",
    "    mode = 'bilinear'\n",
    "    \n",
    "    # Вызов функции e2p\n",
    "    pers_img = e2p(equirectangular_img, fov_deg, u_deg, v_deg, out_hw, in_rot_deg, mode)\n",
    "    bgr_scaled_depth = cv2.cvtColor(scaled_depth, cv2.COLOR_GRAY2BGR)\n",
    "    pers_depth = e2p(bgr_scaled_depth, fov_deg, u_deg, v_deg, out_hw, in_rot_deg, mode)\n",
    "    \n",
    "    # Визуализация результата (при необходимости) \n",
    "    # cv2.imshow('Perspective Image', pers_img)\n",
    "    # cv2.imshow('Perspective Depth', pers_depth)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # Сохранение изображений\n",
    "    cv2.imwrite(f\"frblud/{face_k}_depth.jpg\", pers_depth)\n",
    "    cv2.imwrite(f\"frblud/{face_k}_image.jpg\", pers_img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T12:34:27.037232900Z",
     "start_time": "2024-02-09T12:34:21.293870300Z"
    }
   },
   "id": "99598ad6c734c089",
   "execution_count": 163
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from defisheye import Defisheye\n",
    "import cv2 \n",
    "\n",
    "dtype = 'linear'\n",
    "format = 'fullframe'\n",
    "fov = 160\n",
    "pfov = 90\n",
    "\n",
    "\n",
    "img = \"parts_with_padding/part1.jpg\"\n",
    "\n",
    "obj = Defisheye(pers_img, dtype=dtype, format=format, fov=fov, pfov=pfov)\n",
    "\n",
    "# To use the converted image in memory\n",
    "\n",
    "new_image = obj.convert()\n",
    "\n",
    "cv2.imshow(\"1\", new_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T09:34:32.555041100Z",
     "start_time": "2024-02-09T09:34:29.618051100Z"
    }
   },
   "id": "28225122f3e38178",
   "execution_count": 104
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
